{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series forecasting using Python Pandas and the PI System\n",
    "\n",
    "https://pisquare.osisoft.com/people/epennaz/blog/2015/12/31/a-quick-example-of-time-series-forecasting-using-python-pandas-and-the-pi-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling data from a PI System via the AFSDK into Python (IPython):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************************************************************************************  \n",
    "# ©2009-2015 OSIsoft, LLC. All Rights Reserved.   \n",
    "# No Warranty or Liability.  The OSIsoft Samples contained herein are licensed “AS IS” without any warranty of any kind.    \n",
    "# Licensee bears all risk of use. OSIsoft DISCLAIMS ALL EXPRESS AND IMPLIED WARRANTIES,INCLUDING BUT NOT LIMITED TO THE   \n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE and NONINFRINGEMENT. In no event will OSIsoft  \n",
    "# be liable to Licensee or to any third party for damages of any kind arising from Licensee’s use of the OSIsoft Samples   \n",
    "# OR OTHERWISE, including but not limited to direct, indirect, special, incidental, lost profits and consequential   \n",
    "# damages, and Licensee expressly assumes the risk of all such damages. This limitation applies to any claims related to  \n",
    "# Licensee’s use of the OSIsoft Samples and claims for breach of contract, breach of warranty, guarantee or condition,   \n",
    "# strict liability, negligence or other tort to the extent permitted by applicable law.  This limitation applies even if  \n",
    "# OSIsoft knew or should have known about the possibility of the damages. FURTHER, THE OSIsoft SAMPLES ARE NOT ELIGIBLE   \n",
    "# FOR SUPPORT UNDER EITHER OSISOFT’S STANDARD OR ENTERPRISE LEVEL SUPPORT AGREEMENTS.  \n",
    "#****************************************************************************************  \n",
    "# IPyton  \n",
    "import clr   \n",
    "clr.AddReference(r\"C:\\Program Files (x86)\\PIPC\\AF\\PublicAssemblies\\4.0\\OSIsoft.AFSDK\")  \n",
    "from OSIsoft import AF    \n",
    "import datetime as dt  \n",
    "import time  \n",
    "from pandas.stats.moments import ewma  \n",
    "import pandas as pd  \n",
    "import statsmodels.api as sm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first template element in the default database of the default pi server    \n",
    "piDB = AF.PI.PIServers().DefaultPIServer  \n",
    "piPoint = AF.PI.PIPoint.FindPIPoint(piDB,\"BA:TEMP.1\")  \n",
    "#Set timerange to pull data, using PI Time  \n",
    "startTime = AF.Time.AFTime(\"T-10d\")  \n",
    "endTime = AF.Time.AFTime(\"T\")  \n",
    "timeRange = AF.Time.AFTimeRange(startTime, endTime)  \n",
    "#Set AF boundary type  \n",
    "boundaryType = AF.Data.AFBoundaryType.Inside "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set our prediction times(using PI time)  \n",
    "startPredictTime = AF.Time.AFTime(\"T\")  \n",
    "sp = datetime.datetime.strptime(startPredictTime.LocalTime.ToString(),'%m/%d/%Y %I:%M:%S %p')  \n",
    "endPredictTime = AF.Time.AFTime(\"T+10d\")  \n",
    "ep = datetime.datetime.strptime(endPredictTime.LocalTime.ToString(),'%m/%d/%Y %I:%M:%S %p')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data from the PI Data Archive  \n",
    "#maxCount(50000 here) is not optional  \n",
    "recordedValues = piPoint.RecordedValues(timeRange,boundaryType,\"\",False,50000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the data from PI via the AFSDK, we’re going to format it such that a Python Pandas dataframe can be used. Then, we'll use an auto regressive moving average to predict the future.\n",
    "\n",
    "Here is the Stats Documentation for our example:\n",
    "\n",
    "http://statsmodels.sourceforge.net/devel/examples/notebooks/generated/tsa_arma.html\n",
    "\n",
    "And a Stats Example:\n",
    "\n",
    "http://statsmodels.sourceforge.net/devel/examples/notebooks/generated/tsa_arma_0.html\n",
    "\n",
    "There are a ton of statistical packages for python out there and here were using just one in a large number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary entry for Python  \n",
    "recordedValuesDict = dict()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add all the timestamps and values found to a dict in order to import to pandas  \n",
    "for event in recordedValues:    \n",
    "    dt = datetime.datetime.strptime(event.Timestamp.LocalTime.ToString(),'%m/%d/%Y %I:%M:%S %p')  \n",
    "    recordedValuesDict[dt] = event.Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data  \n",
    "df = pd.DataFrame(recordedValuesDict.items(), columns=['TimeStamp', 'Value'])  \n",
    "#Send it to a dateTime Index then set the index   \n",
    "df['TimeStamp'] = pd.to_datetime(df['TimeStamp'])  \n",
    "indexed_df = df.set_index(['TimeStamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exponential SMoothing  \n",
    "dfewma = pd.ewma(indexed_df,span=1,freq='H')  \n",
    "dfewma.plot()  \n",
    "ar_model = sm.tsa.AR(dfewma, freq='H')  \n",
    "pandas_ar_res = ar_model.fit(maxlag=200, method='cmle', disp=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need an overlap in the prediction space(Add automatic upabove)  \n",
    "pred = pandas_ar_res.predict(start=str(sp), end=str(ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out the plot to take a look at it  \n",
    "print pred.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can export this predicted data to a future data PI tag and save it back to the PI Data Archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send Data to the PI Data Archive  \n",
    "#Get Pi point to send data to, this should already be created as a future data point  \n",
    "#alternatively you can create this automatically and search it  \n",
    "piPointPredict = AF.PI.PIPoint.FindPIPoint(piDB,\"BA:Temp.1_Future\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data from Pred data frame to AF Values  \n",
    "newValues = AF.Asset.AFValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TimeStamps and Values  \n",
    "for index,Value in enumerate(pred):  \n",
    "    newValue = AF.Asset.AFValue()  \n",
    "    newValue.Timestamp = AF.Time.AFTime(pred.index[index].to_datetime().strftime('%m/%d/%Y %I:%M:%S %p'))  \n",
    "    newValue.Value = float(Value)  \n",
    "    newValues.Add(newValue) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AFUpdateOption  \n",
    "updateOption = AF.Data.AFUpdateOption.InsertNoCompression  \n",
    "#AFBufferOption  \n",
    "bufferOption = AF.Data.AFBufferOption.BufferIfPossible  \n",
    "#Write data from AF Values into PI  \n",
    "piPointPredict.UpdateValues(newValues, updateOption, bufferOption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
